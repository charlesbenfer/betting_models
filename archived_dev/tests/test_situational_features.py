"""
Test Situational Features
========================

Test the new situational context features to ensure they work correctly.
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime
import sys

# Import our modules
from config import config
from dataset_builder import PregameDatasetBuilder
from modeling import EnhancedDualModelSystem

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_situational_features():
    """Test the new situational context features."""
    logger.info("="*70)
    logger.info("TESTING SITUATIONAL CONTEXT FEATURES")
    logger.info("="*70)
    
    try:
        # Build dataset with situational features
        logger.info("Building dataset with new situational features...")
        builder = PregameDatasetBuilder(
            start_date="2024-08-01", 
            end_date="2024-08-15"
        )
        
        # Build dataset 
        dataset = builder.build_dataset(force_rebuild=True)
        
        if dataset.empty:
            logger.error("Dataset is empty - cannot test features")
            return False
        
        logger.info(f"Dataset built: {len(dataset)} rows, {len(dataset.columns)} columns")
        
        # Check for situational features
        analyze_situational_features(dataset)
        
        # Test model integration
        test_model_integration(dataset)
        
        # Analyze feature quality
        analyze_feature_quality(dataset)
        
        logger.info("\nSituational feature testing completed successfully!")
        return True
        
    except Exception as e:
        logger.error(f"Situational feature testing failed: {e}")
        return False

def analyze_situational_features(dataset: pd.DataFrame):
    """Analyze the situational features in the dataset."""
    logger.info("\n" + "="*60)
    logger.info("SITUATIONAL FEATURE ANALYSIS")
    logger.info("="*60)
    
    # Find situational features
    expected_situational = config.SITUATIONAL_FEATURES
    found_situational = []
    missing_situational = []
    
    for feature in expected_situational:
        if feature in dataset.columns:
            found_situational.append(feature)
        else:
            missing_situational.append(feature)
    
    logger.info(f"Expected situational features: {len(expected_situational)}")
    logger.info(f"Found features: {len(found_situational)}")
    logger.info(f"Missing features: {len(missing_situational)}")
    
    if found_situational:
        logger.info(f"\nFound situational features: {found_situational[:10]}...")  # Show first 10
    
    if missing_situational:
        logger.warning(f"Missing situational features: {missing_situational}")
    
    # Show total feature count increase
    all_features = [col for col in dataset.columns if col not in 
                   ['date', 'batter', 'pitcher', 'game_pk', 'season', 'hit_hr', 'home_runs']]
    logger.info(f"\nTotal features in dataset: {len(all_features)}")
    
    return found_situational

def analyze_feature_quality(dataset: pd.DataFrame):
    """Analyze the quality of situational features."""
    logger.info("\n" + "="*60)
    logger.info("FEATURE QUALITY ANALYSIS")
    logger.info("="*60)
    
    # Analyze key situational features
    key_features = [
        'avg_runners_on_base', 'risp_percentage', 'clutch_hr_rate',
        'late_inning_hr_rate', 'pressure_performance_index',
        'hitters_count_hr_rate', 'leverage_performance_ratio'
    ]
    
    for feature in key_features:
        if feature in dataset.columns:
            feature_data = dataset[feature]
            non_null = feature_data.notna().sum()
            non_zero = (feature_data > 0).sum()
            
            logger.info(f"\n{feature}:")
            logger.info(f"  Coverage: {non_null/len(dataset):.1%} ({non_null}/{len(dataset)})")
            logger.info(f"  Non-zero: {non_zero/len(dataset):.1%} ({non_zero}/{len(dataset)})")
            
            if non_null > 0:
                stats = feature_data.describe()
                logger.info(f"  Mean: {stats['mean']:.4f}")
                logger.info(f"  Std: {stats['std']:.4f}")
                logger.info(f"  Min: {stats['min']:.4f}")
                logger.info(f"  Max: {stats['max']:.4f}")
                logger.info(f"  Unique values: {feature_data.nunique()}")
                
                # Check for reasonable values
                if 'hr_rate' in feature and stats['max'] > 1.0:
                    logger.warning(f"  WARNING: HR rates > 100% found (max: {stats['max']:.4f})")
                
                if 'percentage' in feature and stats['max'] > 1.0:
                    logger.warning(f"  WARNING: Percentages > 100% found (max: {stats['max']:.4f})")

def test_model_integration(dataset: pd.DataFrame):
    """Test that situational features integrate with the model system."""
    logger.info("\n" + "="*60)
    logger.info("MODEL INTEGRATION TEST")
    logger.info("="*60)
    
    try:
        # Initialize model system
        model_system = EnhancedDualModelSystem()
        
        # Check feature identification
        available_features = model_system.feature_selector.identify_available_features(dataset)
        
        logger.info(f"Feature breakdown:")
        logger.info(f"  Core features: {len(available_features['core'])}")
        logger.info(f"  Bat tracking features: {len(available_features.get('bat_tracking', []))}")
        logger.info(f"  Matchup features: {len(available_features.get('matchup', []))}")
        logger.info(f"  Situational features: {len(available_features.get('situational', []))}")
        logger.info(f"  Enhanced features total: {len(available_features['enhanced'])}")
        
        # Show some situational features
        situational_features = available_features.get('situational', [])
        if situational_features:
            logger.info(f"\nSituational features found: {len(situational_features)}")
            logger.info(f"Examples: {situational_features[:8]}")
        else:
            logger.warning("No situational features detected in model system!")
        
        # Quick training test if we have enough data
        if len(dataset) > 100:
            logger.info("\nTesting model training with situational features...")
            
            # Use small sample for quick test
            test_data = dataset.head(200).copy()
            
            # Ensure target variable
            if 'hit_hr' not in test_data.columns:
                if 'home_runs' in test_data.columns:
                    test_data['hit_hr'] = (test_data['home_runs'] > 0).astype(int)
                else:
                    test_data['hit_hr'] = np.random.binomial(1, 0.1, len(test_data))
            
            # Try training
            try:
                results = model_system.fit(
                    test_data,
                    splitting_strategy='random',
                    test_size=0.3,
                    val_size=0.2,
                    cross_validate=False
                )
                
                logger.info("Model training with situational features successful!")
                logger.info(f"Enhanced features used: {len(available_features['enhanced'])}")
                
            except Exception as train_error:
                logger.error(f"Model training failed: {train_error}")
        
    except Exception as e:
        logger.error(f"Model integration test failed: {e}")

def analyze_feature_correlations(dataset: pd.DataFrame):
    """Analyze correlations between situational features and home runs."""
    logger.info("\n" + "="*60)
    logger.info("FEATURE CORRELATION ANALYSIS")
    logger.info("="*60)
    
    if 'hit_hr' not in dataset.columns:
        logger.warning("No target variable for correlation analysis")
        return
    
    # Get situational features with good coverage
    situational_features = [col for col in dataset.columns 
                          if any(feat in col for feat in ['clutch', 'pressure', 'leverage', 'inning', 'count'])]
    
    meaningful_features = []
    for feature in situational_features:
        non_null_pct = dataset[feature].notna().mean()
        if non_null_pct > 0.8:  # At least 80% coverage
            meaningful_features.append(feature)
    
    if not meaningful_features:
        logger.warning("No situational features with sufficient coverage for correlation analysis")
        return
    
    logger.info(f"Analyzing correlations for {len(meaningful_features)} features")
    
    correlations = []
    for feature in meaningful_features:
        corr = dataset[feature].corr(dataset['hit_hr'])
        if not pd.isna(corr):
            correlations.append((feature, corr))
    
    # Sort by absolute correlation
    correlations.sort(key=lambda x: abs(x[1]), reverse=True)
    
    logger.info(f"\nTop situational feature correlations with home runs:")
    for i, (feature, corr) in enumerate(correlations[:10], 1):
        logger.info(f"  {i:2d}. {feature}: {corr:+.4f}")

def compare_feature_sets():
    """Compare dataset with and without situational features."""
    logger.info("\n" + "="*60)
    logger.info("FEATURE SET COMPARISON")
    logger.info("="*60)
    
    # Compare expected vs actual feature counts
    expected_counts = {
        'Core features': len(config.CORE_FEATURES),
        'Bat tracking features': len(config.BAT_TRACKING_FEATURES),
        'Matchup features': len(config.MATCHUP_FEATURES),
        'Situational features': len(config.SITUATIONAL_FEATURES)
    }
    
    logger.info("Expected feature counts:")
    total_expected = 0
    for category, count in expected_counts.items():
        logger.info(f"  {category}: {count}")
        total_expected += count
    
    logger.info(f"  Total expected new features: {total_expected}")
    
    # Load current dataset to see actual counts
    try:
        dataset = pd.read_parquet('data/processed/pregame_dataset_2024-08-01_2024-08-15.parquet')
        feature_cols = [col for col in dataset.columns if col not in 
                       ['date', 'batter', 'pitcher', 'game_pk', 'season', 'hit_hr', 'home_runs', 'batter_name']]
        
        logger.info(f"\nActual dataset:")
        logger.info(f"  Total feature columns: {len(feature_cols)}")
        logger.info(f"  Total rows: {len(dataset)}")
        
        # Count by feature type
        matchup_cols = [col for col in feature_cols if 'matchup' in col or 'vs_similar' in col]
        situational_cols = [col for col in feature_cols if any(x in col for x in 
                           ['clutch', 'pressure', 'leverage', 'inning', 'count', 'risp', 'runners'])]
        
        logger.info(f"  Matchup features found: {len(matchup_cols)}")
        logger.info(f"  Situational features found: {len(situational_cols)}")
        
    except Exception as e:
        logger.warning(f"Could not load dataset for comparison: {e}")

def main():
    """Main testing function."""
    logger.info("Starting situational features testing...")
    
    success = test_situational_features()
    
    if success:
        # Additional analysis
        try:
            dataset = pd.read_parquet('data/processed/pregame_dataset_2024-08-01_2024-08-15.parquet')
            analyze_feature_correlations(dataset)
        except Exception as e:
            logger.warning(f"Could not run correlation analysis: {e}")
        
        compare_feature_sets()
        
        logger.info("\n" + "="*70)
        logger.info("âœ… SITUATIONAL FEATURES TESTING COMPLETED!")
        logger.info("Step 2 implementation successful.")
        logger.info("="*70)
        return 0
    else:
        logger.error("\nSituational features testing failed!")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)