"""
Production Model Export Test
============================

Test script to verify model export/import functionality and measure inference speed.
"""

import time
import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import List, Tuple

from modeling import EnhancedDualModelSystem
from inference_features import ProductionInferenceExample
from config import config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionExportTester:
    """Test production model export and inference speed."""
    
    def __init__(self, model_dir: str = None):
        self.model_dir = Path(model_dir or config.MODEL_DIR)
        self.test_results = {}
    
    def test_model_export(self) -> bool:
        """Test model export functionality."""
        logger.info("Testing model export functionality...")
        
        try:
            # Load existing model
            model_system = EnhancedDualModelSystem(str(self.model_dir))
            model_system.load()
            
            # Verify models loaded
            if model_system.core_model is None and model_system.enhanced_model is None:
                logger.warning("No trained models found - training is required first")
                logger.info("To train a model, run: python main.py train --start-date 2024-06-01 --end-date 2024-08-31")
                self.test_results['export_test'] = 'skipped_no_model'
                return False
            
            # Test save functionality (should already exist)
            model_system.save()
            
            # Test reload
            model_system_copy = EnhancedDualModelSystem(str(self.model_dir))
            model_system_copy.load()
            
            # Verify reload worked
            success = (
                (model_system.core_model is None) == (model_system_copy.core_model is None) and
                (model_system.enhanced_model is None) == (model_system_copy.enhanced_model is None)
            )
            
            if success:
                logger.info("‚úÖ Model export/import test passed")
                self.test_results['export_test'] = True
            else:
                logger.error("‚ùå Model export/import test failed")
                self.test_results['export_test'] = False
            
            return success
            
        except Exception as e:
            logger.error(f"Model export test failed: {e}")
            self.test_results['export_test'] = False
            return False
    
    def test_inference_speed(self, num_predictions: int = 100) -> dict:
        """Test model inference speed."""
        logger.info(f"Testing inference speed with {num_predictions} predictions...")
        
        try:
            # Load model
            model_system = EnhancedDualModelSystem(str(self.model_dir))
            model_system.load()
            
            if model_system.core_model is None and model_system.enhanced_model is None:
                logger.error("No trained models available for speed test")
                return {}
            
            # Create sample data for testing
            sample_pairs = [(i, i+1000) for i in range(400000, 400000 + num_predictions)]
            
            # Initialize inference system
            inference_system = ProductionInferenceExample()
            
            # Time the prediction process
            start_time = time.time()
            
            try:
                predictions_df = inference_system.predict_todays_games(
                    model_system, 
                    sample_pairs
                )
                
                end_time = time.time()
                total_time = end_time - start_time
                
                speed_stats = {
                    'total_predictions': len(predictions_df),
                    'total_time_seconds': round(total_time, 3),
                    'predictions_per_second': round(len(predictions_df) / total_time, 2),
                    'ms_per_prediction': round((total_time * 1000) / len(predictions_df), 3),
                    'model_type': 'enhanced' if model_system.enhanced_model else 'core'
                }
                
                logger.info(f"‚úÖ Inference speed test completed:")
                logger.info(f"   - {speed_stats['predictions_per_second']} predictions/second")
                logger.info(f"   - {speed_stats['ms_per_prediction']} ms per prediction")
                logger.info(f"   - Using {speed_stats['model_type']} model")
                
                self.test_results['inference_speed'] = speed_stats
                return speed_stats
                
            except Exception as e:
                logger.error(f"Prediction failed during speed test: {e}")
                # Try with a smaller sample if prediction fails
                logger.info("Trying with smaller sample...")
                
                small_sample = sample_pairs[:10]
                start_time = time.time()
                predictions_df = inference_system.predict_todays_games(model_system, small_sample)
                end_time = time.time()
                
                total_time = end_time - start_time
                speed_stats = {
                    'total_predictions': len(predictions_df),
                    'total_time_seconds': round(total_time, 3),
                    'predictions_per_second': round(len(predictions_df) / total_time, 2) if total_time > 0 else 0,
                    'ms_per_prediction': round((total_time * 1000) / len(predictions_df), 3) if len(predictions_df) > 0 else 0,
                    'model_type': 'enhanced' if model_system.enhanced_model else 'core',
                    'note': 'Small sample due to prediction issues'
                }
                
                self.test_results['inference_speed'] = speed_stats
                return speed_stats
                
        except Exception as e:
            logger.error(f"Inference speed test failed: {e}")
            self.test_results['inference_speed'] = {'error': str(e)}
            return {}
    
    def test_model_validation(self) -> bool:
        """Validate that loaded models work correctly."""
        logger.info("Testing model validation...")
        
        try:
            model_system = EnhancedDualModelSystem(str(self.model_dir))
            model_system.load()
            
            if model_system.core_model is None and model_system.enhanced_model is None:
                logger.error("No models available for validation")
                return False
            
            # Get model info
            if model_system.enhanced_model:
                features_count = len(model_system.available_features.get('enhanced', []))
                model_type = 'enhanced'
            else:
                features_count = len(model_system.available_features.get('core', []))
                model_type = 'core'
            
            validation_info = {
                'model_type': model_type,
                'feature_count': features_count,
                'model_dir': str(self.model_dir),
                'metadata': model_system.metadata
            }
            
            logger.info(f"‚úÖ Model validation passed:")
            logger.info(f"   - Model type: {model_type}")
            logger.info(f"   - Feature count: {features_count}")
            logger.info(f"   - Last trained: {model_system.metadata.get('training_timestamp', 'Unknown')}")
            
            self.test_results['validation'] = validation_info
            return True
            
        except Exception as e:
            logger.error(f"Model validation failed: {e}")
            self.test_results['validation'] = {'error': str(e)}
            return False
    
    def run_full_test_suite(self) -> dict:
        """Run complete production export test suite."""
        logger.info("üöÄ Starting production export test suite...")
        
        # Test 1: Model export/import
        export_success = self.test_model_export()
        
        # Test 2: Model validation  
        validation_success = self.test_model_validation()
        
        # Test 3: Inference speed
        speed_results = self.test_inference_speed(50)  # Start with smaller sample
        
        # Summary
        all_passed = (
            export_success and 
            validation_success and 
            bool(speed_results)
        )
        
        summary = {
            'overall_success': all_passed,
            'export_test': export_success,
            'validation_test': validation_success,
            'speed_test_results': speed_results,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        if all_passed:
            logger.info("üéâ All production export tests PASSED!")
        else:
            logger.warning("‚ö†Ô∏è  Some production export tests FAILED")
        
        return summary

def main():
    """Run production export tests."""
    tester = ProductionExportTester()
    results = tester.run_full_test_suite()
    
    print("\n" + "="*60)
    print("PRODUCTION EXPORT TEST RESULTS")
    print("="*60)
    print(f"Overall Success: {'‚úÖ PASS' if results['overall_success'] else '‚ùå FAIL'}")
    print(f"Export Test: {'‚úÖ PASS' if results['export_test'] else '‚ùå FAIL'}")
    print(f"Validation Test: {'‚úÖ PASS' if results['validation_test'] else '‚ùå FAIL'}")
    
    if results['speed_test_results']:
        speed = results['speed_test_results']
        print(f"Speed Test: ‚úÖ PASS")
        print(f"  - {speed.get('predictions_per_second', 0)} predictions/second")
        print(f"  - {speed.get('ms_per_prediction', 0)} ms per prediction")
    else:
        print(f"Speed Test: ‚ùå FAIL")
    
    print("="*60)
    
    return results

if __name__ == "__main__":
    main()